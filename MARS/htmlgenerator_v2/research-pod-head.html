				<tr>
					<td align=center>
						<table width=700px>
							<tr>
								<td>
									<!--
									<img src='/MARS/img/w_bg.gif' width=1px height=50px><br>
									<span class=mars3t><b>Research</b></span><br>
									-->
									<img src='/MARS/img/w_bg.gif' width=1px height=50px><br>
									<table width=100% cellpadding=0 cellspacing=0>
										<tr>
											<td colspan=2 align=center>
												<span class=mars3t><font size=5><b>POD: A Highly-Efficient 3D-Integrated <br>Heterogeneous Many-core Architecture</b></font></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=50px><br>
											</td>
										</tr>
										<tr>
											<td>
												<span class=mars3t><b>Faculty</b></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
												<span class=mars3_><a href='http://users.ece.gatech.edu/~leehs/'>Hsien-Hsin Sean Lee</a></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=30px><br>
												<span class=mars3t><b>Graduate Students</b></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
												<span class=mars3_><a href='http://arch.ece.gatech.edu/people/Dong_Hyuk.html'>Dong Hyuk Woo</a></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=30px><br>
												<span class=mars3t><b>External Collaborators</b></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
												<span class=mars3_>Marsha Eng (Intel Corporation)</span><br>
												<span class=mars3_>Joshua B. Fryman (Intel Corporation)</span><br>
												<span class=mars3_>Allan D. Knies (Intel Research Berkeley)</span><br>

												<img src='/MARS/img/w_bg.gif' width=1px height=30px><br>
												<span class=mars3t><b>Sponsor</b></span><br>
                                                                                                <img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
												<table>
													<tr align=center>
														<td>
                                                                                                			<a href='http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0811738'><img src='/MARS/img/nsf-logo.jpg' align=center border=0></a>
														</td>
													</tr>
													<tr align=center>
														<td>
															<span class=mars3_>NSF CPA</span>
														</td>
													</tr>

												</table>
											</td>
											<td align=right>
												<a href='/MARS/img/pod_arch.gif' target=_blank><img src='/MARS/img/pod_arch.gif' width=448px border=0></a>
											</td>
										</tr>
									</table>
									<img src='/MARS/img/w_bg.gif' width=1px height=30px><br>
									<table width=100% cellpadding=0 cellspacing=0>
										<tr>
											<td align='justify'>
												<span class=mars3t><b>Description</b></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
<span class=mars3_>
To feature hundreds or even thousands of processing cores on a single-die many-core processor, the challenges of energy consumption and performance scalability must be addressed within a given die area budget. Current commercial designs focus on MIMD-style multicores built with rather complex cores. While such designs provide a degree of generality, they may not be the most efficient way to build processors for applications with inherently scalable parallelism.<br><br>
In this research, we revisit the massively parallel SIMD processing paradigm with modern process technology and present a highly efficient on-chip accelerator architecture called Parallel-On-Die (or POD). Leveraging from emerging 3D integration, POD is designed to address the key challenges of overall chip power, on-chip communication bandwidth, area limitations, and energy consumed by routers by factoring out features necessary for normal MIMD-style many-core platform and focusing on architectures that match scalable workloads. Its deterministic computation and  communication model offers much better energy efficiency while also providing a fully debuggable programming environment to application developers. Our single-chip POD is capable of best-in-class scalar performance as well as extremely efficient, scalable parallel performance up to 1.5 TFLOPS of single-precision  oating-point arithmetic. Our experimental results show that POD can achieve nearly linear speedup on a large number of SIMD PEs in some application domains, and this speedup is much bigger than the maximum speedup a homogeneous MIMD many-core processor can offer. Using the metric of Performance per Joule, we show that POD also improves the computation-energy efficiency substantially over a homogeneous many-core processor. Furthermore, owing to synchronized computation and communication, POD can efficiently suppress energy consumption on the novel communication method in our proposed interconnection network.<br>
</span>
												<img src='/MARS/img/w_bg.gif' width=1px height=30px><br>
												<span class=mars3t><b>Technical Presentation</b></span><br>
												<img src='/MARS/img/w_bg.gif' width=1px height=10px><br>
												<span class=mars3_>
												An overview slide is available <a href='http://arch.ece.gatech.edu/present/POD-overview.ppt'>here</a>.
												</span>

											</td>
										</tr>
